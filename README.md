# Spotify - Previs√£o de Popularidade de M√∫sicas

Um projeto de **Machine Learning** para classificar o sucesso de uma m√∫sica com base em suas caracter√≠sticas sonoras.

---

## √çndice
1. [Contexto do Projeto](#contexto-do-projeto)  
2. [An√°lise Explorat√≥ria de Dados (EDA) - Principais Insights](#an√°lise-explorat√≥ria-de-dados-eda---principais-insights)  
3. [Pr√©-processamento e Modelagem](#pr√©-processamento-e-modelagem)  
4. [Resultados e Compara√ß√£o de Modelos](#resultados-e-compara√ß√£o-de-modelos)  
5. [Conclus√£o](#conclus√£o)  
6. [Ferramentas Utilizadas](#ferramentas-utilizadas)  
7. [Autor](#autor)  

---

## 1. Contexto do Projeto
A ind√∫stria musical √© um mercado extremamente competitivo e saturado. Diariamente, milhares de novas m√∫sicas s√£o lan√ßadas, mas apenas uma pequena fra√ß√£o atinge um n√≠vel significativo de popularidade. Para gravadoras, artistas e curadores de playlists, entender os ingredientes de um "hit" √© um desafio que vale milh√µes.

Este projeto busca resolver esse desafio atrav√©s da ci√™ncia de dados.  
O objetivo √© construir e avaliar um **modelo de Machine Learning de classifica√ß√£o** capaz de prever se uma m√∫sica tem potencial para se tornar um sucesso, com base exclusivamente em suas caracter√≠sticas sonoras quantific√°veis, como **dan√ßabilidade, energia, tom e val√™ncia**.

üîó [Base de Dados](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset)
---

## 2. An√°lise Explorat√≥ria de Dados (EDA) - Principais Insights

Antes da modelagem, uma an√°lise profunda foi realizada para entender a natureza dos dados e extrair insights valiosos.

- **Defini√ß√£o de "Hit"**: Para transformar o problema em uma classifica√ß√£o bin√°ria, um "hit" foi definido como qualquer m√∫sica pertencente ao **Top 10% de popularidade** do dataset. Com base na distribui√ß√£o, isso corresponde a um score de popularidade >= 63.  

- **Desbalanceamento de Classes**: A an√°lise revelou um forte desbalanceamento entre as classes, refletindo a realidade do mercado: existem muito mais m√∫sicas "n√£o populares" do que hits.  

- **A "Assinatura Sonora" de um Hit**:  
  M√∫sicas de sucesso tendem a ser:  
  - Mais **Dan√ßantes** (*danceability*) e **Energ√©ticas** (*energy*)  
  - Mais **Altas** (*loudness*)  
  - Significativamente menos **Ac√∫sticas** (*acousticness*) e **Instrumentais** (*instrumentalness*)  

- **Correla√ß√µes**: Nenhuma caracter√≠stica sonora sozinha possui correla√ß√£o forte o suficiente para prever o sucesso, refor√ßando a necessidade de um modelo capaz de aprender com a intera√ß√£o entre m√∫ltiplas **features**.

---

## 3. Pr√©-processamento e Modelagem

A prepara√ß√£o dos dados para o treinamento seguiu as melhores pr√°ticas:

1. **Limpeza e Sele√ß√£o de Features**: Remo√ß√£o de colunas n√£o informativas (IDs, nomes, datas).  
2. **Pr√©-processamento Avan√ßado**: Utiliza√ß√£o de `ColumnTransformer` para aplicar tratamentos distintos por tipo de vari√°vel.  
   - **Num√©ricas**: Normalizadas com `StandardScaler`.  
   - **Categ√≥ricas** (`key`, `time_signature`): Convertidas com `OneHotEncoder`.  
3. **Divis√£o dos Dados**: 80% treino e 20% teste, utilizando `stratify` para manter a propor√ß√£o de classes.  
4. **Modelos Testados**: Regress√£o Log√≠stica, Random Forest e XGBoost.  

---

## 4. Resultados e Compara√ß√£o de Modelos

A performance de cada modelo foi avaliada com foco na identifica√ß√£o da classe **'popular'**.  
O **Random Forest** foi o vencedor, apresentando melhor equil√≠brio entre as m√©tricas.

| Modelo                | Precision (popular) | Recall (popular) | F1-Score (popular) |
|------------------------|---------------------|------------------|--------------------|
| Regress√£o Log√≠stica    | 0.00                | 0.00             | 0.00               |
| Random Forest (Baseline) | 0.93              | 0.55             | 0.69               |
| XGBoost               | 0.80                | 0.08             | 0.14               |

### Otimizando o Random Forest
Para melhorar o **recall**, o modelo foi re-treinado com `class_weight='balanced'`.

| Vers√£o do Random Forest | Precision (popular) | Recall (popular) | F1-Score (popular) |
|--------------------------|---------------------|------------------|--------------------|
| Baseline                 | 0.93                | 0.55             | 0.69               |
| Com `class_weight`       | 0.82                | 0.57             | 0.68               |

üîπ O ajuste aumentou o recall (55% ‚Üí 57%), mas reduziu a precis√£o (93% ‚Üí 82%), evidenciando o **trade-off cl√°ssico em Machine Learning**.

---

## 5. Conclus√£o

A an√°lise mostrou que √© poss√≠vel prever o potencial de sucesso de uma m√∫sica com um bom grau de confian√ßa usando apenas suas caracter√≠sticas sonoras.  
O **Random Forest** superou a Regress√£o Log√≠stica e o XGBoost.

- Para tarefas que exigem **alta confian√ßa** (ex: criar playlists "Top Hits"), o **modelo baseline** √© ideal.  
- Para tarefas de **descoberta** (ex: ca√ßa-talentos), o modelo ajustado com `class_weight` √© mais √∫til, mesmo com mais falsos positivos.  

### Pr√≥ximos Passos
- **Ajuste de Hiperpar√¢metros**: Utilizar `GridSearchCV` ou `RandomizedSearchCV`.  
- **Engenharia de Features**: Incluir informa√ß√µes sobre o artista (ex: n√∫mero de seguidores) ou aplicar **NLP** √†s letras.  

---

## 6. Ferramentas Utilizadas
- **Linguagem**: Python  
- **Bibliotecas**: Pandas, NumPy, Scikit-learn, XGBoost, Matplotlib, Seaborn  
- **Ambiente**: Google Colab  

---

## 7. Autor
Matheus Mendon√ßa Sucupira Lima  

üîó [LinkedIn](www.linkedin.com/in/matheusmendoncasucupira)  
üîó [GitHub](https://github.com/MMENDONNCA)  

